# Introduction

In-context learning refers to the ability of a neural network to learn from information presented in its context \cite{brown2020language}. While traditional learning in neural networks requires adjusting network weights for every new task, in-context learning operates purely by updating internal activations without needing any updates to network weights. The emergence of this ability in large language models has led to a paradigm shift in machine learning and has forced researchers to reconceptualize how they think about learning in neural networks. Looking beyond language models, we can find in-context learning in many computational models relevant to cognitive science, including those that emerge from meta-learning \cite{binz2023meta}. 

The present workshop aims to delineate and discuss the implications of this phenomenon for the cognitive sciences. In order to accomplish this goal, we have invited experts who will present recent advances on the topic of \emph{in-context learning in natural and artificial intelligence}. The selected speakers cover a broad spectrum of topics, including (a) understanding in-context learning from a computational perspective \cite{chan2022data}, (b) using in-context learning to model human behavior \cite{binz2022heuristics}, and (c) applications in neuroscience and linguistics \cite{ whittington2023prefrontal}. 

There is growing evidence for the presence of in-context learning-like systems in humans \cite{binz2023meta}. In contrast to traditional learning schemes for neural networks, in-context learning is fast and sample-efficient, and thereby able to capture the human ability to learn from just a few observations. It accomplishes this by having learned (in its weights) the inductive biases relevant to the environment it operates in. In-context learning is therefore able to exploit environmental structures such as learning curricula \cite{flesch2018comparing} or compositional representations \cite{lake2023human} to learn rapidly from a few examples. Taken together, these features offer a new perspective on many aspects of human cognition --- some of which we will cover in our workshop.

# Speakers

### Akshay K. Jagadish (Organizer) 
Akshay K. Jagadish is a PhD student at the Max Planck Institute for Biological Cybernetics, T Ìˆubingen. His current research is dedicated towards understanding the ingredients essential for explaining human adaptive behavior across multiple task domains.

### Ishita Dasgupta (Organizer) 
Ishita Dasgupta is a research scientist at Google Deepmind. She uses advances in machine learning to build models of human reasoning, applies cognitive science approaches toward understanding black-box AI systems, and combines these insights to build better, more human-like artificial intelligence.

# Program

| Time        | Speaker          | Title | Description |
|:-------------|:------------------|:------|:----|
| 14h           | Akshay K. Jagadish | Ecologically rational meta-learned inference explains human category learning  |d|
| 15h | Ishita Dasgupta   | Concepts and categories within context  |d|

 

